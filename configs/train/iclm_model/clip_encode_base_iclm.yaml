_target_: src.models.sen_img_caption_iclm.SenImgEncodeCaptionICLM

lm_config: 
  vocab_size: 118287
  n_embd: 512
  n_head: 8
  n_layer: 2
clip_name: openai/clip-vit-base-patch32


